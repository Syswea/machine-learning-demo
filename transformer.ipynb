{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31cc22e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "357a1182",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "LOOKBACK = 30\n",
    "FORECAST = 7\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "torch.random.manual_seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34d9a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, num_features, d_model=512):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.linear = nn.Linear(num_features, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0bb8fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model=512, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        encoding = encoding.unsqueeze(0)\n",
    "\n",
    "        # Register the encoding as a buffer so it is not a model parameter\n",
    "        self.register_buffer('encoding', encoding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:, :x.size(1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7296ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model=512, num_heads=8, dropout=0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Q的形状: [batch_size, num_heads, seq_len, d_k]\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # 如果提供了mask，则将其应用于注意力分数\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "            \n",
    "        # 应用softmax获取注意力权重\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.drop(attn_weights)\n",
    "        \n",
    "        # 应用注意力权重到值(V)\n",
    "        output = torch.matmul(attn_weights, V)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        # 输入x的形状: [batch_size, seq_len, d_model]\n",
    "        batch_size, seq_len = x.size(0), x.size(1)\n",
    "        \n",
    "        # 重塑为 [batch_size, seq_len, num_heads, d_k]\n",
    "        x = x.view(batch_size, seq_len, self.num_heads, self.d_k)\n",
    "        \n",
    "        # 转置为 [batch_size, num_heads, seq_len, d_k]\n",
    "        return x.transpose(1, 2)\n",
    "    \n",
    "    def combine_heads(self, x):\n",
    "        # 输入x的形状: [batch_size, num_heads, seq_len, d_k]\n",
    "        batch_size, _, seq_len = x.size(0), x.size(1), x.size(2)\n",
    "        \n",
    "        # 转置回 [batch_size, seq_len, num_heads, d_k]\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # 重塑为 [batch_size, seq_len, d_model]\n",
    "        return x.contiguous().view(batch_size, seq_len, self.d_model)\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        \n",
    "        # 线性变换\n",
    "        Q = self.W_q(query)\n",
    "        K = self.W_k(key)\n",
    "        V = self.W_v(value)\n",
    "        \n",
    "        # 分割头\n",
    "        Q = self.split_heads(Q)\n",
    "        K = self.split_heads(K)\n",
    "        V = self.split_heads(V)\n",
    "        \n",
    "        # 应用缩放点积注意力\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # 合并头\n",
    "        output = self.combine_heads(attn_output)\n",
    "        \n",
    "        # 最终线性变换\n",
    "        output = self.W_o(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c30e0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model=512, d_ff=2048):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.activation = nn.GELU()\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abf6b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model=512, num_heads=8, d_ff=2048, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.self_attn(x, x, x)\n",
    "        x = self.drop(x)\n",
    "        x = self.norm1(x + residual)\n",
    "        \n",
    "        residual = x\n",
    "        x = self.feed_forward(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.norm2(x + residual)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef371208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_feature,num_layers=6, d_model=512, num_heads=8, d_ff=2048, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = Embedding(num_feature,d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.drop(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba857f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model=512, num_heads=8, d_ff=2048, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encode_ouput, mask):\n",
    "        residual = x\n",
    "        x = self.self_attn(x, x, x, mask)\n",
    "        x = self.drop(x)\n",
    "        x = self.norm1(x + residual)\n",
    "        \n",
    "        residual = x\n",
    "        x = self.enc_dec_attn(x, encode_ouput, encode_ouput)\n",
    "        x = self.drop(x)\n",
    "        x = self.norm2(x + residual)\n",
    "        \n",
    "        residual = x\n",
    "        x = self.feed_forward(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.norm3(x + residual)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff51f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_feature,num_layers=6, d_model=512, num_heads=8, d_ff=2048, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = Embedding(num_feature,d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc = nn.Linear(d_model, num_feature)\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, mask):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.drop(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_output, mask)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c2e5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = torch.triu(torch.ones(size, size), diagonal=1).type(torch.uint8)\n",
    "    return mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57661e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(encoder, decoder, inputs, infer_steps):\n",
    "    \"\"\"\n",
    "    inputs: [1, seq_len, num_features]\n",
    "    results: [infer_steps, num_features]\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        shift_outputs = inputs[:, -1:, :]\n",
    "\n",
    "        encode = encoder(inputs)\n",
    "        for _ in range(infer_steps):\n",
    "            mask_size = shift_outputs.size(1)\n",
    "            mask = create_look_ahead_mask(mask_size)\n",
    "\n",
    "            decode = decoder(shift_outputs, encode, mask)\n",
    "\n",
    "            results.append(decode[:, -1, :])\n",
    "\n",
    "            shift_outputs = torch.cat((shift_outputs, decode[:, -1, :].unsqueeze(1)), dim=1)\n",
    "\n",
    "    return torch.cat(results, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92070bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, lookback, forecast):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - lookback - forecast + 1):\n",
    "        X.append(data[i:i+lookback])\n",
    "        y.append(data[i+lookback:i+lookback+forecast])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec5f0394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_loader():\n",
    "    import baostock as bs\n",
    "    import pandas as pd\n",
    "    \n",
    "    bs.login()\n",
    "    rs = bs.query_history_k_data_plus(\"sh.600000\",\n",
    "        \"date,code,open,high,low,close,preclose,volume,amount,adjustflag,turn,tradestatus,pctChg,isST\",\n",
    "        start_date='2020-01-01', end_date='2023-12-31',\n",
    "        frequency=\"d\", adjustflag=\"3\")\n",
    "    data_list = []\n",
    "    while (rs.error_code == '0') & rs.next():\n",
    "        data_list.append(rs.get_row_data())\n",
    "    df = pd.DataFrame(data_list, columns=rs.fields)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(by='date')\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df[['open', 'high', 'low', 'close', 'volume', 'amount', 'turn', 'pctChg']]\n",
    "    df = df.astype(float)\n",
    "\n",
    "    print(df.head())\n",
    "\n",
    "    bs.logout()\n",
    "\n",
    "    # 归一化\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    data = df.values\n",
    "\n",
    "    X, y = prepare_data(data, LOOKBACK, FORECAST)\n",
    "    \n",
    "    # 先划分训练集和验证集\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED, shuffle=False)\n",
    "\n",
    "    # 只使用训练集来拟合scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train.reshape(-1, X_train.shape[-1]))\n",
    "\n",
    "    # 对训练集和验证集进行转换\n",
    "    X_train = scaler.transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "    X_val = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
    "    y_train = scaler.transform(y_train.reshape(-1, y_train.shape[-1])).reshape(y_train.shape)\n",
    "    y_val = scaler.transform(y_val.reshape(-1, y_val.shape[-1])).reshape(y_val.shape)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4f01bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, train_loader, val_loader, lr, epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    params = list(encoder.parameters()) + list(decoder.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for train_x, train_y in train_loader:\n",
    "            train_x, train_y = train_x.to(device), train_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            enc_output = encoder(train_x)\n",
    "\n",
    "            mask_size = train_y.size(1)\n",
    "            mask = create_look_ahead_mask(mask_size).to(device)\n",
    "\n",
    "            decoder_input = torch.cat([train_x[:, -1:, :], train_y[:, :-1, :]], dim=1)\n",
    "\n",
    "            dec_output = decoder(decoder_input, enc_output, mask)\n",
    "\n",
    "            loss = criterion(dec_output, train_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_x, val_y in val_loader:\n",
    "                val_x, val_y = val_x.to(device), val_y.to(device)\n",
    "\n",
    "                enc_output = encoder(val_x)\n",
    "\n",
    "                mask_size = val_y.size(1)\n",
    "                mask = create_look_ahead_mask(mask_size).to(device)\n",
    "\n",
    "                decoder_input = torch.cat([val_x[:, -1:, :], val_y[:, :-1, :]], dim=1)\n",
    "\n",
    "                dec_output = decoder(decoder_input, enc_output, mask)\n",
    "\n",
    "                loss = criterion(dec_output, val_y)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ab64611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login success!\n",
      "    open   high    low  close      volume       amount    turn  pctChg\n",
      "0  12.47  12.64  12.45  12.47  51629079.0  647446166.0  0.1837  0.8084\n",
      "1  12.57  12.63  12.47  12.60  38018810.0  477053357.0  0.1353  1.0425\n",
      "2  12.52  12.65  12.42  12.46  41001193.0  514432551.0  0.1459 -1.1111\n",
      "3  12.51  12.60  12.46  12.50  28421482.0  355811756.0  0.1011  0.3210\n",
      "4  12.41  12.45  12.25  12.32  35240536.0  434980266.0  0.1254 -1.4400\n",
      "logout success!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 获取数据\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_loader, val_loader, scaler = \u001b[43mfetch_data_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 获取特征数量\u001b[39;00m\n\u001b[32m      5\u001b[39m num_features = train_loader.dataset[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m].shape[-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mfetch_data_loader\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     44\u001b[39m y_train = scaler.transform(y_train.reshape(-\u001b[32m1\u001b[39m, y_train.shape[-\u001b[32m1\u001b[39m])).reshape(y_train.shape)\n\u001b[32m     45\u001b[39m y_val = scaler.transform(y_val.reshape(-\u001b[32m1\u001b[39m, y_val.shape[-\u001b[32m1\u001b[39m])).reshape(y_val.shape)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m train_dataset = \u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m val_dataset = TensorDataset(X_val, y_val)\n\u001b[32m     50\u001b[39m train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/qenv/lib/python3.11/site-packages/torch/utils/data/dataset.py:205\u001b[39m, in \u001b[36mTensorDataset.__init__\u001b[39m\u001b[34m(self, *tensors)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *tensors: Tensor) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mSize mismatch between tensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28mself\u001b[39m.tensors = tensors\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/qenv/lib/python3.11/site-packages/torch/utils/data/dataset.py:206\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *tensors: Tensor) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         \u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m == tensor.size(\u001b[32m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors\n\u001b[32m    207\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33mSize mismatch between tensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28mself\u001b[39m.tensors = tensors\n",
      "\u001b[31mTypeError\u001b[39m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "# 获取数据\n",
    "train_loader, val_loader, scaler = fetch_data_loader()\n",
    "\n",
    "# 获取特征数量\n",
    "num_features = train_loader.dataset[0][0].shape[-1]\n",
    "\n",
    "# 初始化模型\n",
    "encoder = Encoder(num_features)\n",
    "decoder = Decoder(num_features)\n",
    "\n",
    "# 训练模型\n",
    "train(encoder, decoder, train_loader, val_loader, lr=0.0001, epochs=50)\n",
    "\n",
    "# 示例推理\n",
    "# 获取一个样本进行推理\n",
    "sample_input, _ = val_loader.dataset[0]\n",
    "sample_input = sample_input.unsqueeze(0)  # 添加批次维度\n",
    "\n",
    "predictions = infer(encoder, decoder, sample_input, FORECAST)\n",
    "\n",
    "# 反归一化预测结果\n",
    "predictions = scaler.inverse_transform(predictions.cpu().numpy())\n",
    "\n",
    "print(\"Predictions:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
